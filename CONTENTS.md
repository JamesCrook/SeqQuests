# Project Contents and User Guide

This suite of tools is designed for protein sequence analysis, specifically focusing on high-performance local similarity comparisons (Smith-Waterman) and phylogenetic tree construction using Swiss-Prot data.

## 1. Core Applications

### Web Dashboard
**Entry Point:** `python py/web_server.py` (Run from project root)
**URL:** `http://localhost:8000` (Default)
**Status:** Mature
**Description:** A FastAPI-based web server that provides a dashboard for managing analysis jobs. It allows you to configure and run Data Munging, Computation (Tree Building), and Sequence Search jobs.

### Sequence Search (NWS)
**Executable:** `bin/metal_nws` (Compiled from `c_src/metal_nws.mm`)
**Python Wrapper:** `py/nws_search.py`
**Status:** Mature (High Performance)
**Description:** A Metal-accelerated (GPU) implementation of the Needleman-Wunsch-Smith algorithm. It performs massive parallel searches of a query sequence against a database.
*   **Usage:** Typically invoked via the Web Dashboard. Can be run standalone via CLI.
*   **Data:** Requires binary compiled data (`fasta.bin`, `pam250.bin`) generated by `c_src/prepare_data.py`.

### Tree Builder
**Script:** `py/tree_builder.py`
**Backend:** `bin/tree_builder_cpp` (Optional C++ acceleration)
**Status:** Active
**Description:** Constructs Minimum Spanning Trees (MST) from protein sequence data.
*   **Usage:** Configurable via `py/computation.py` jobs in the dashboard.

### Data Munger
**Script:** `py/data_munger.py`
**Status:** Active
**Description:** Filters and processes raw Swiss-Prot data to extract relevant proteins based on criteria (e.g., taxonomy, existence of GO terms).

## 2. Python Modules (`py/`)

*   **`job_manager.py`**: The orchestration engine. Manages the lifecycle (start, stop, status) of background jobs triggered by the web server.
*   **`sequences.py`**: The data access layer. Abstracts reading from Swiss-Prot (`.dat`) and FASTA files. Handles caching (Pickle) and Indexing for performance.
*   **`seq_align.py`**: A pure Python implementation of Smith-Waterman. Useful for debugging and verifying scores against the Metal implementation.
*   **`pam_converter.py`**: Utility to convert Biopython's PAM250 matrix into the specific 32x32 integer format required by the Metal kernel.

## 3. Metal & C++ Source (`c_src/`, `metal/`)

*   **`c_src/metal_nws.mm`**: The production C++/Metal implementation of the search algorithm.
*   **`c_src/nws.metal`**: The Metal shader kernel code.
*   **`metal/metal_nws.py`**: **Prototype.** A Python implementation that mimics the Metal kernel logic. Useful for debugging the algorithm logic without a GPU.

## 4. Web Interface (`static/`)

Contains the frontend code (HTML/JS) for the dashboard.
*   `index.html`: Main layout.
*   `jobs.html`: Job list and creation.
*   `config_*.html`: Configuration forms for specific job types.

## 5. System Architecture

1.  **User** interacts with **Web Dashboard**.
2.  **Web Server** creates a **Job** via **Job Manager**.
3.  **Job** runs a specific script or executable:
    *   *Search Job* -> Wraps `bin/metal_nws`.
    *   *Computation Job* -> Runs `py/tree_builder.py`.
    *   *Data Job* -> Runs `py/data_munger.py`.
4.  **Results** are monitored via the Dashboard.

## 6. Setup & Compilation

*   **Compile Native Code:** Run `./compile.sh` to build `bin/metal_nws` and `bin/tree_builder_cpp`.
*   **Python Path:** Ensure `PYTHONPATH` includes the `py/` directory (e.g., `PYTHONPATH=py python py/web_server.py`).
